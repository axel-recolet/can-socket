/\*\*

- Document d'analyse des optimisations possibles pour can-socket
  \*/

# Optimisations des performances Neon TypeScript

## R√©sultats des benchmarks (Raspberry Pi)

### Performances actuelles mesur√©es

- **Rust natif** : 157,000+ frames/sec (envoi), 13,000+ frames/sec (r√©ception)
- **TypeScript Neon** : ~217 frames/sec
- **Ratio de performance** : TypeScript est ~723x plus lent que Rust natif

### Tests d'optimisation JavaScript

Les micro-benchmarks sur Raspberry Pi montrent :

- **Pool d'objets** : -55.6% (contre-productif pour petits objets)
- **Traitement par lots** : -220% (overhead JS trop important)
- **Pool de buffers** : +20% (seule optimisation b√©n√©fique)
- **Am√©lioration totale estim√©e** : +6.7% ‚Üí ~231 fps

## Analyse des goulots d'√©tranglement

### 1. Conversions Neon (90% du co√ªt)

Le principal limitant est la conversion Rust ‚Üî JavaScript :

```rust
// Co√ªteux - conversion par √©l√©ment
for (i, byte) in data.iter().enumerate() {
    let js_byte = cx.number(*byte as f64);  // Allocation JS
    js_data.set(&mut cx, i as u32, js_byte)?; // Appel JS
}
```

### 2. Allocations m√©moire JavaScript

Chaque frame cr√©e plusieurs objets temporaires :

```typescript
// Co√ªteux - nouvelles allocations
const frame = {
    id: number,           // Nouvelle propri√©t√©
    data: number[],       // Nouveau array
    extended: boolean,    // Nouveau boolean
    // ...
};
```

### 3. Overhead de l'event loop

Les appels asynchrones ajoutent de la latence :

```typescript
// Chaque await ajoute ~1ms de latence minimum
const frame = await socket.receive(timeout);
```

## Optimisations impl√©ment√©es

### ‚úÖ 1. Pool d'objets de frames

```typescript
class FramePool {
  private pool: AnyCanFrame[] = [];

  getFrame(): AnyCanFrame {
    return this.pool.pop() || this.createFrame();
  }

  returnFrame(frame: AnyCanFrame): void {
    // Reset et r√©utilisation
    this.resetFrame(frame);
    this.pool.push(frame);
  }
}
```

### ‚úÖ 2. Batching automatique des envois

```typescript
private sendBuffer: FrameData[] = [];
private batchSize = 50;

async send(id: number, data: number[]): Promise<void> {
    this.sendBuffer.push({id, data});

    if (this.sendBuffer.length >= this.batchSize) {
        await this.flushBatch(); // Envoi group√©
    }
}
```

### ‚úÖ 3. Pr√©-chargement des r√©ceptions

```typescript
private readBuffer: AnyCanFrame[] = [];

async receive(): Promise<AnyCanFrame> {
    // Retourner du buffer d'abord
    if (this.readBuffer.length > 0) {
        return this.readBuffer.shift()!;
    }

    // Sinon lire nouveau
    return await this.readFromNative();
}
```

### ‚úÖ 4. G√©n√©rateur asynchrone optimis√©

```typescript
async* frames(options?: {prefetch?: number}): AsyncGenerator<AnyCanFrame> {
    const prefetchSize = options?.prefetch ?? 10;

    while (true) {
        // Pr√©-charger en lot si possible
        if (this.readBuffer.length < prefetchSize) {
            await this.prefetchFrames();
        }

        yield await this.receive();
    }
}
```

## Optimisations futures n√©cessaires

### üéØ 1. Optimisations Neon critiques (Impact: 10-50x)

#### A. ArrayBuffer zero-copy

```rust
// Au lieu de copier √©l√©ment par √©l√©ment
fn create_frame_buffer(mut cx: FunctionContext, data: &[u8]) -> JsResult<JsArrayBuffer> {
    let buffer = cx.array_buffer(data.len())?;
    cx.borrow_mut(&buffer, |handle| {
        handle.as_mut_slice().copy_from_slice(data); // Copie directe
    });
    Ok(buffer)
}
```

#### B. Fonctions batch natives

```rust
// Traitement de lots en Rust pour √©viter les aller-retours JS
fn send_frames_batch(mut cx: FunctionContext) -> JsResult<JsUndefined> {
    let frames_array = cx.argument::<JsArray>(1)?;

    // Traiter tous les frames en Rust sans retour JS
    for i in 0..frames_array.len(&mut cx) {
        // Process frame entirely in Rust
    }
}

fn read_frames_batch(mut cx: FunctionContext) -> JsResult<JsArray> {
    let max_frames = cx.argument::<JsNumber>(1)?.value(&mut cx) as usize;
    // Lire plusieurs frames d'un coup
}
```

#### C. Cache de frames pr√©-compil√©es

```rust
// Pool de frames Rust r√©utilisables
lazy_static! {
    static ref FRAME_CACHE: Mutex<Vec<PreparedFrame>> =
        Mutex::new(Vec::new());
}

struct PreparedFrame {
    js_object: Handle<JsObject>,
    js_data_array: Handle<JsArray>,
}
```

### üéØ 2. Optimisations syst√®me (Impact: 2-5x)

#### A. Configuration SocketCAN

```bash
# Optimiser les buffers du noyau
echo 'net.core.rmem_max = 134217728' >> /etc/sysctl.conf
echo 'net.core.wmem_max = 134217728' >> /etc/sysctl.conf

# Files CAN plus importantes
ip link set can0 txqueuelen 1000
```

#### B. Configuration Node.js

```bash
# Optimiser V8 pour performance
node --max-old-space-size=4096 \
     --optimize-for-size \
     --expose-gc \
     app.js
```

#### C. Workers threads pour parall√©lisation

```typescript
// S√©parer envoi/r√©ception sur threads diff√©rents
const sendWorker = new Worker("./send-worker.js");
const receiveWorker = new Worker("./receive-worker.js");
```

## Estimations d'am√©lioration r√©alistes

### Court terme (optimisations TypeScript uniquement)

- **Impl√©mentation actuelle** : 217 fps
- **Avec optimisations TS** : 231 fps (+6.7%)
- **Gains identifi√©s** : Pool de buffers seulement

### Moyen terme (optimisations Neon basiques)

- **ArrayBuffer zero-copy** : 231 fps ‚Üí 700 fps (+200%)
- **Batch send/receive** : 700 fps ‚Üí 2,100 fps (+200%)
- **Total estim√©** : **2,100 fps** (10x am√©lioration)

### Long terme (optimisations avanc√©es)

- **Cache de frames** : 2,100 fps ‚Üí 3,150 fps (+50%)
- **Optimisations syst√®me** : 3,150 fps ‚Üí 6,300 fps (+100%)
- **Workers parall√®les** : 6,300 fps ‚Üí 10,000 fps (+60%)
- **Total estim√©** : **10,000 fps** (46x am√©lioration)

## Comparaison avec exigences r√©elles

### Capacit√©s des bus CAN

- **CAN 2.0** : 500 fps maximum th√©orique
- **CAN FD** : 5,000 fps maximum th√©orique

### √âtat vs objectifs

- **Actuel (217 fps)** : ‚úÖ Suffisant pour CAN 2.0
- **Court terme (231 fps)** : ‚úÖ Bon pour CAN 2.0
- **Moyen terme (2,100 fps)** : ‚úÖ Excellent pour CAN 2.0, suffisant pour CAN FD
- **Long terme (10,000 fps)** : ‚úÖ D√©passe CAN FD, id√©al pour haute performance

## Roadmap d'impl√©mentation

### Phase 1 : Optimisations imm√©diates (1 semaine)

1. ‚úÖ Pool d'objets TypeScript (d√©j√† fait)
2. ‚úÖ Batching automatique (d√©j√† fait)
3. ‚úÖ Buffer de lecture (d√©j√† fait)
4. üîÑ Tests de performance complets

### Phase 2 : Optimisations Neon (2-3 semaines)

1. üéØ ArrayBuffer pour donn√©es (priorit√© max)
2. üéØ Fonctions batch natives send/receive
3. üéØ R√©duction des conversions Rust‚ÜîJS

### Phase 3 : Optimisations avanc√©es (1 mois)

1. Cache de frames pr√©-compil√©es
2. Workers threads pour parall√©lisation
3. Optimisations syst√®me et noyau

### Phase 4 : Tests et validation (1 semaine)

1. Benchmarks complets
2. Tests sur mat√©riel CAN r√©el
3. Validation des gains de performance

## Conclusion

**Les performances actuelles (217 fps) sont d√©j√† acceptables** pour la plupart des applications CAN r√©elles. Cependant, des am√©liorations significatives sont possibles :

- **Gain rapide** : +6.7% avec optimisations TypeScript seules
- **Gain r√©aliste** : +900% avec optimisations Neon moyennes
- **Gain maximum** : +4500% avec optimisations compl√®tes

Les **optimisations Neon sont critiques** car elles s'attaquent au vrai goulot d'√©tranglement (conversions Rust‚ÜîJS), tandis que les optimisations TypeScript ont un impact limit√©.
